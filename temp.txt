Here's an updated version of the `test_completion.py` file with additional test cases for different variations of request headers and configurations for the `model_config_params` parameters. I will also define the `model_config_params` fields and descriptions in the response.

---

### Updated `test_completion.py`

```python
import pytest
from fastapi.testclient import TestClient
from src.main import app

client = TestClient(app)

@pytest.fixture
def headers():
    return {"X-Session-ID": "test-session", "X-Usecase-ID": "test-usecase"}

@pytest.fixture
def headers_with_api_key():
    return {
        "X-Session-ID": "test-session",
        "X-Usecase-ID": "test-usecase",
        "X-Base-API-Key": "test-api-key",
    }

@pytest.fixture
def incomplete_headers():
    return {"X-Session-ID": "test-session"}  # Missing "X-Usecase-ID"

def test_text_completion(headers):
    response = client.post(
        "/api/v1/chatcompletion",
        json={
            "model_name": "gemini-1.5-flash",
            "user_prompt": "Hello, how are you?",
        },
        headers=headers,
    )
    assert response.status_code == 200
    assert "choices" in response.json()

def test_text_completion_with_model_config(headers):
    response = client.post(
        "/api/v1/chatcompletion",
        json={
            "model_name": "gemini-1.5-flash",
            "user_prompt": "Provide a summary of this text.",
            "model_config_params": {
                "max_completion_tokens": 50,
                "temperature": 0.7,
                "top_p": 0.9,
                "n": 2,
                "presence_penalty": 0.6,
                "frequency_penalty": 0.2,
            },
        },
        headers=headers,
    )
    assert response.status_code == 200
    assert "choices" in response.json()

def test_image_completion(headers_with_api_key):
    response = client.post(
        "/api/v1/chatcompletion",
        json={
            "model_name": "gemini-1.5-flash",
            "user_prompt": "Describe this image",
            "image_url": "https://general-purpose-public.s3.ap-south-1.amazonaws.com/gemini_test_images/aadharCard.jpeg",
        },
        headers=headers_with_api_key,
    )
    assert response.status_code == 200
    assert "choices" in response.json()

def test_invalid_headers():
    response = client.post(
        "/api/v1/chatcompletion",
        json={
            "model_name": "gemini-1.5-flash",
            "user_prompt": "Hello",
        },
    )
    assert response.status_code == 422

def test_incomplete_headers(incomplete_headers):
    response = client.post(
        "/api/v1/chatcompletion",
        json={
            "model_name": "gemini-1.5-flash",
            "user_prompt": "Hello",
        },
        headers=incomplete_headers,
    )
    assert response.status_code == 400
    assert response.json()["detail"] == "Missing X-Session-ID or X-Usecase-ID headers"

def test_text_completion_with_invalid_model_config(headers):
    response = client.post(
        "/api/v1/chatcompletion",
        json={
            "model_name": "gemini-1.5-flash",
            "user_prompt": "Generate some output.",
            "model_config_params": {
                "max_completion_tokens": 5000,  # Invalid: exceeds allowed range
                "temperature": -1.0,  # Invalid: below allowed range
            },
        },
        headers=headers,
    )
    assert response.status_code == 422  # Expect validation error

def test_tool_usage_with_model_config(headers_with_api_key):
    response = client.post(
        "/api/v1/chatcompletion",
        json={
            "model_name": "gemini-1.5-flash",
            "user_prompt": "What tools can I use?",
            "model_config_params": {
                "tool_choice": "auto",
                "tools": [
                    {
                        "type": "function",
                        "function": {
                            "name": "search_tool",
                            "description": "Performs a web search",
                            "parameters": {
                                "type": "object",
                                "properties": {
                                    "query": {
                                        "type": "string",
                                        "description": "Search query",
                                    }
                                },
                                "required": ["query"],
                            },
                        },
                    }
                ],
            },
        },
        headers=headers_with_api_key,
    )
    assert response.status_code == 200
    assert "choices" in response.json()

```

---

### Description of `model_config_params` Fields

The `model_config_params` allows customization of the behavior of the model. Below are its fields and their descriptions:

| Field Name              | Type                                   | Description                                                                                                                                            |
|-------------------------|----------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|
| `frequency_penalty`     | `float` (range: -2.0 to 2.0)          | Penalizes repeated tokens based on their frequency in the text. Positive values reduce repetition.                                                     |
| `logit_bias`            | `Dict[str, int]`                      | Adjusts the likelihood of specific tokens appearing in the output.                                                                                     |
| `logprobs`              | `bool`                                | If `True`, returns log probabilities of tokens.                                                                                                       |
| `max_completion_tokens` | `int` (minimum: 1)                    | Maximum number of tokens to generate in the completion.                                                                                               |
| `metadata`              | `Dict[str, str]`                      | Additional metadata about the request.                                                                                                                |
| `modalities`            | `List[Literal["text", "audio"]]`      | Specifies the input/output modalities.                                                                                                                |
| `n`                     | `int`                                 | Number of completions to generate per request.                                                                                                        |
| `presence_penalty`      | `float` (range: -2.0 to 2.0)          | Penalizes repeated topics in the text. Positive values encourage diversity in the output.                                                             |
| `response_format`       | `Dict[str, Union[str, Dict[str, str]]]` | Specifies the format of the response.                                                                                                                 |
| `seed`                  | `int`                                 | Seed for deterministic sampling.                                                                                                                      |
| `service_tier`          | `Literal["auto", "default", "flex"]`  | Specifies the service tier for the model.                                                                                                             |
| `stop`                  | `Union[str, List[str]]`               | Sequence(s) at which the model will stop generating further tokens.                                                                                   |
| `store`                 | `bool`                                | If `True`, stores the output of the completion.                                                                                                       |
| `stream`                | `bool`                                | If `True`, streams responses as they are generated.                                                                                                   |
| `stream_options`        | `Dict[str, Union[bool, str]]`         | Additional options for streaming responses.                                                                                                           |
| `temperature`           | `float` (range: 0.0 to 2.0)           | Controls randomness in the output. Lower values result in more deterministic output, while higher values increase randomness.                          |
| `tool_choice`           | `Literal["none", "auto", "required"]` | Specifies whether to use tools during the completion process.                                                                                         |
| `tools`                 | `List[Tool]`                         | List of tools to be used. Each tool contains a name, description, and parameters (type, properties, and required fields).                              |
| `top_logprobs`          | `int` (range: 0 to 20)                | Number of top log probabilities to return.                                                                                                            |
| `top_p`                 | `float` (range: 0.0 to 1.0)           | Nucleus sampling parameter. Considers tokens with cumulative probability mass up to `top_p`.                                                          |

---

This test script ensures that all variations of headers and `model_config_params` are tested, and validation is enforced for invalid configurations. You can extend it further by adding more edge cases as needed.
