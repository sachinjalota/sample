I need to create a service using FastAPI. This service is basically a benchmarking service for LLM models. What I need to do in this is to test a open source LLM models against a subscribed LLM models such as gemini, chatgpt and others. Now these benchmarks should consider all the possible criteria that the llms are evaluated on. You can either create a code from scratch for this or use an existing framework that can sit well in FastAPI client process.

Few benchmarks that I can think of is as follows, you are free to add as many as per the importance
1. Tokens per second generated,
2. speed
3. accuracy


Give me a very detailed plan for this with proper codes and explanation for each benchmarks suggested and why you suggested it and how it is interpreted.
